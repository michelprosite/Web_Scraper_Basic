{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Web Scraping com Python\n",
    "\n",
    "## Michel Souza Santana\n",
    "\n",
    "* Data de início: 09 de maio de 2023\n",
    "\n",
    "* Duração: 60 horas\n",
    "\n",
    "> Descrição: \n",
    "\n",
    "Este curso irá ensinar a você os fundamentos do Web Scraping utilizando a linguagem de programação Python. Com o aumento da quantidade de dados disponíveis na internet, a habilidade de coletar e analisar informações da web é cada vez mais valorizada no mercado de trabalho. Neste curso, você irá aprender desde os conceitos básicos de HTML e CSS até a utilização de bibliotecas como requests, Beautiful Soup e Selenium para coletar e analisar dados de páginas web. Além disso, também iremos abordar boas práticas de Web Scraping ético e o armazenamento de dados. Ao final do curso, você estará pronto para desenvolver seu próprio Web Scraper e aplicar seus conhecimentos em projetos reais.\n",
    "\n",
    "> Autor: \n",
    "\n",
    "Michel Souza Santana é formado em Análise e Desenvolvimento de Sistemas e atua na área de Engenharia de Dados há mais de 5 anos, com experiência em coleta e análise de dados de diferentes fontes. Além disso, é entusiasta da tecnologia e das possibilidades que a análise de dados pode trazer para as empresas e para a sociedade em geral.\n",
    "\n",
    "Este curso é ideal para estudantes, analistas de dados, desenvolvedores e qualquer pessoa que queira aprender a coletar e analisar informações da web de forma automatizada. Não é necessário conhecimento prévio em Web Scraping ou Python, mas é recomendado que você tenha um conhecimento básico em programação."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice:\n",
    "\n",
    "* 1 - Introdução ao Web Scraping\n",
    "    * 1.1 O que é Web Scraping?\n",
    "    * 1.2 Por que é importante?\n",
    "    * 1.3 Ferramentas para Web Scraping\n",
    ">...   \n",
    "\n",
    "* 2 - HTML básico e CSS\n",
    "    * 2.1 Estrutura de uma página HTML\n",
    "    * 2.2 Tags HTML básicas\n",
    "    * 2.3 CSS para estilização de páginas\n",
    ">...\n",
    "\n",
    "* 3 - Requisições HTTP e Biblioteca requests\n",
    "    * 3.1 O que é uma requisição HTTP?\n",
    "    * 3.2 Biblioteca requests em Python\n",
    "    * 3.3 Fazendo uma requisição HTTP em Python\n",
    "    * 3.4 Tratando erros com try/except\n",
    ">...\n",
    "\n",
    "* 4 - Analisando HTML com Beautiful Soup\n",
    "    * 4.1 O que é Beautiful Soup?\n",
    "    * 4.2 Analisando HTML com Beautiful Soup\n",
    "    * 4.3 Buscando elementos HTML específicos\n",
    "    * 4.4 Tratando erros com try/except\n",
    ">...\n",
    "\n",
    "* 5 - Armazenamento de dados\n",
    "    * 6.1 Formatos de dados comuns\n",
    "    * 6.2 Armazenando dados em um arquivo CSV\n",
    "    * 6.3 Armazenando dados em um banco de dados\n",
    ">...\n",
    "\n",
    "* 6 - Introdução ao Web Scraping Ético\n",
    "    * 7.1 O que é Web Scraping ético?\n",
    "    * 7.2 Legislação sobre Web Scraping\n",
    "    * 7.3 Boas práticas de Web Scraping ético\n",
    ">...\n",
    "\n",
    "* 7 - Projeto Final\n",
    "    * 8.1 Desenvolvendo um Web Scraper completo\n",
    "    * 8.2 Implementando o armazenamento de dados\n",
    "    * 8.3 Tratando erros com try/except\n",
    "    * 8.4 Boas práticas de Web Scraping ético\n",
    ">..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Introdução ao Web Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 O que é Web Scraping?\n",
    "\n",
    "Web Scraping é uma técnica utilizada para extrair informações de páginas da web de forma automatizada. Ela permite que os dados sejam coletados de maneira mais rápida e eficiente do que se fosse feito manualmente.\n",
    "\n",
    "Imagine que você precisa coletar informações de diversos sites para realizar uma pesquisa de mercado. Fazer isso manualmente seria uma tarefa demorada e tediosa, pois você teria que entrar em cada página, encontrar as informações desejadas e copiá-las para um documento.\n",
    "\n",
    "Com o Web Scraping, é possível automatizar todo esse processo. Você pode escrever um programa que acesse as páginas da web, procure as informações desejadas e as salve em um formato estruturado, como um arquivo CSV ou um banco de dados.\n",
    "\n",
    "Existem diversas ferramentas e bibliotecas que podem ser utilizadas para aplicar a técnica de Web Scraping, como a biblioteca requests e a biblioteca Beautiful Soup em Python, além do Selenium para Web Scraping dinâmico.\n",
    "\n",
    "Há inúmeros exemplos em que o Web Scraping pode ser aplicado. Uma das aplicações mais comuns é a coleta de informações de sites de e-commerce para análise de preços e concorrência. Imagine que você é proprietário de uma loja virtual e precisa manter seus preços competitivos em relação aos concorrentes. Com o Web Scraping, é possível coletar automaticamente os preços dos produtos de seus concorrentes e analisá-los em um formato estruturado, permitindo que você tome decisões estratégicas com base nessas informações.\n",
    "\n",
    "Outro exemplo de aplicação do Web Scraping é na área de análise de dados e pesquisa de mercado. Muitas empresas precisam coletar informações de diferentes fontes para realizar análises de mercado e identificar tendências. Com o Web Scraping, é possível automatizar esse processo e coletar as informações desejadas de maneira mais rápida e eficiente.\n",
    "\n",
    "É importante ressaltar que o Web Scraping deve ser feito com responsabilidade e ética, respeitando as políticas de privacidade dos sites e a legislação vigente. Por isso, é fundamental entender as boas práticas de Web Scraping ético e aplicá-las em seus projetos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Por que é importante?\n",
    "\n",
    "Web Scraping é uma técnica poderosa que pode ajudar a coletar e analisar informações de uma ampla variedade de fontes na web. Ele permite que você automatize tarefas que seriam demoradas ou impossíveis de realizar manualmente, tornando o processo de coleta de dados mais rápido, eficiente e preciso.\n",
    "\n",
    "A capacidade de extrair informações da web pode ser extremamente valiosa em diversos setores, incluindo negócios, pesquisa científica, análise de mercado, jornalismo, entre outros. Por exemplo, em uma empresa de análise de dados, o Web Scraping pode ser usado para coletar informações de diferentes fontes, como sites de notícias, blogs e redes sociais, e integrá-las em um formato estruturado para análise. Isso pode ajudar a empresa a identificar tendências, padrões e insights importantes que podem ser usados para tomar decisões mais informadas e baseadas em dados.\n",
    "\n",
    "Além disso, o Web Scraping pode ser usado para automatizar processos em diferentes setores. Por exemplo, em uma loja online, o Web Scraping pode ser usado para coletar informações sobre preços e estoques de produtos de concorrentes e atualizar automaticamente os preços e estoques da loja em conformidade. Isso pode ajudar a loja a manter seus preços competitivos e aumentar suas vendas.\n",
    "\n",
    "No entanto, é importante lembrar que o Web Scraping também apresenta desafios. Por exemplo, é preciso lidar com grandes volumes de dados, bem como questões legais e éticas, como violação de direitos autorais e privacidade. É importante estar ciente desses desafios e estar em conformidade com as leis e regulamentos aplicáveis ao usar o Web Scraping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ferramentas para Web Scraping\n",
    "\n",
    "As ferramentas para Web Scraping são importantes porque facilitam o processo de extração de dados de uma página da web. Existem diversas opções disponíveis no mercado, desde ferramentas simples que podem ser usadas por iniciantes até ferramentas mais avançadas que oferecem uma ampla gama de recursos.\n",
    "\n",
    "Algumas das ferramentas mais populares para Web Scraping incluem BeautifulSoup, Scrapy, Selenium e Requests. Cada uma dessas ferramentas tem suas próprias vantagens e desvantagens, e é importante escolher a que melhor se adapta às suas necessidades específicas.\n",
    "\n",
    "O BeautifulSoup, por exemplo, é uma biblioteca Python que é amplamente utilizada para analisar e extrair dados de páginas HTML e XML. É conhecida por sua facilidade de uso e flexibilidade, tornando-a uma escolha popular entre os desenvolvedores.\n",
    "\n",
    "O Scrapy, por outro lado, é um framework mais avançado que oferece muitos recursos para automatizar a extração de dados da web. É particularmente útil para a extração de grandes quantidades de dados de sites complexos.\n",
    "\n",
    "O Selenium é uma ferramenta útil para Web Scraping dinâmico, ou seja, para extrair dados de páginas que mudam dinamicamente. Ele simula a interação humana com o navegador, permitindo que você extraia dados de páginas que não podem ser facilmente acessadas usando ferramentas convencionais.\n",
    "\n",
    "Já o Requests é uma biblioteca Python simples que permite enviar solicitações HTTP e obter informações de uma página da web. É uma escolha popular para tarefas simples de Web Scraping e é fácil de usar.\n",
    "\n",
    "Independentemente da ferramenta escolhida, é importante lembrar que o Web Scraping deve ser realizado de forma ética e respeitando as leis e direitos autorais."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - HTML básico e CSS\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Estrutura de uma página HTML\n",
    "\n",
    "A estrutura de uma página HTML (Hypertext Markup Language) é fundamental para entender como realizar o Web Scraping em uma página. O HTML é a linguagem de marcação usada para criar páginas web e é composto por elementos que fornecem informações sobre a estrutura e o conteúdo da página.\n",
    "\n",
    "A estrutura básica de uma página HTML inclui a tag < html>, que define o início e o fim do documento HTML, e a tag < body>, que contém o conteúdo visível da página, como texto, imagens, links e outros elementos.\n",
    "\n",
    "Dentro do < body> é possível incluir outras tags HTML que irão definir a estrutura do conteúdo da página. Por exemplo, a tag < header> é usada para definir o cabeçalho da página, enquanto a tag < footer> é usada para definir o rodapé.\n",
    "\n",
    "Além disso, é possível usar as tags < div> e < span> para agrupar elementos em blocos ou em linhas. Esses elementos podem ser estilizados com CSS (Cascading Style Sheets) para melhorar a aparência da página.\n",
    "\n",
    "Por exemplo, imagine que você deseje extrair informações de um site de notícias. Ao analisar a estrutura da página HTML, você pode identificar as tags usadas para exibir os títulos das notícias, a data de publicação e o corpo da matéria. Com essas informações, é possível criar um script de Web Scraping que coleta as notícias e as armazena em um arquivo CSV ou em um banco de dados.\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exemplo de código de uma págia html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<!DOCTYPE html>\\n<html>\\n<head>\\n\\t<title>Título da Página</title>\\n\\t<meta charset=\"UTF-8\">\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n\\t<link rel=\"stylesheet\" type=\"text/css\" href=\"estilos.css\">\\n</head>\\n<body>\\n\\t<header>\\n\\t\\t<h1>Meu Site</h1>\\n\\t\\t<nav>\\n\\t\\t\\t<ul>\\n\\t\\t\\t\\t<li><a href=\"#\">Home</a></li>\\n\\t\\t\\t\\t<li><a href=\"#\">Sobre</a></li>\\n\\t\\t\\t\\t<li><a href=\"#\">Contato</a></li>\\n\\t\\t\\t</ul>\\n\\t\\t</nav>\\n\\t</header>\\n\\t<main>\\n\\t\\t<section>\\n\\t\\t\\t<h2>Seção 1</h2>\\n\\t\\t\\t<p>Conteúdo da seção 1.</p>\\n\\t\\t</section>\\n\\t\\t<section>\\n\\t\\t\\t<h2>Seção 2</h2>\\n\\t\\t\\t<p>Conteúdo da seção 2.</p>\\n\\t\\t</section>\\n\\t</main>\\n\\t<footer>\\n\\t\\t<p>Direitos reservados &copy; 2023</p>\\n\\t</footer>\\n</body>\\n</html>\\n\\n'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "\t<title>Título da Página</title>\n",
    "\t<meta charset=\"UTF-8\">\n",
    "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "\t<link rel=\"stylesheet\" type=\"text/css\" href=\"estilos.css\">\n",
    "</head>\n",
    "<body>\n",
    "\t<header>\n",
    "\t\t<h1>Meu Site</h1>\n",
    "\t\t<nav>\n",
    "\t\t\t<ul>\n",
    "\t\t\t\t<li><a href=\"#\">Home</a></li>\n",
    "\t\t\t\t<li><a href=\"#\">Sobre</a></li>\n",
    "\t\t\t\t<li><a href=\"#\">Contato</a></li>\n",
    "\t\t\t</ul>\n",
    "\t\t</nav>\n",
    "\t</header>\n",
    "\t<main>\n",
    "\t\t<section>\n",
    "\t\t\t<h2>Seção 1</h2>\n",
    "\t\t\t<p>Conteúdo da seção 1.</p>\n",
    "\t\t</section>\n",
    "\t\t<section>\n",
    "\t\t\t<h2>Seção 2</h2>\n",
    "\t\t\t<p>Conteúdo da seção 2.</p>\n",
    "\t\t</section>\n",
    "\t</main>\n",
    "\t<footer>\n",
    "\t\t<p>Direitos reservados &copy; 2023</p>\n",
    "\t</footer>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tags HTML \n",
    "\n",
    "As tags HTML são elementos fundamentais para a construção de páginas web. Elas definem a estrutura e o conteúdo da página, permitindo que os navegadores interpretem e exibam o conteúdo de forma correta. Algumas das tags HTML básicas incluem:\n",
    "\n",
    "< html>: Define o início e o fim do documento HTML.\n",
    "\n",
    "< head>: Contém informações sobre o documento, como o título e o CSS.\n",
    "\n",
    "< body>: Define o conteúdo principal da página.\n",
    "\n",
    "< h1> a < h6>: São utilizadas para criar títulos e subtítulos na página.\n",
    "\n",
    "< p>: É utilizada para criar parágrafos na página.\n",
    "\n",
    "< a>: É utilizada para criar links na página.\n",
    "\n",
    "< img>: É utilizada para inserir imagens na página.\n",
    "\n",
    "< ul> e < ol>: São utilizadas para criar listas não-ordenadas e ordenadas, respectivamente.\n",
    "\n",
    "< li>: É utilizada para criar itens de lista.\n",
    "\n",
    "Essas são apenas algumas das tags HTML básicas, existem muitas outras que podem ser utilizadas para criar páginas web mais complexas e ricas em conteúdo.\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CSS para estilização de \n",
    "\n",
    "O CSS (Cascading Style Sheets) é uma linguagem utilizada para estilizar páginas web. Ela permite definir como os elementos HTML devem ser exibidos na página, controlando aspectos como cores, fontes, tamanhos, posicionamento e outros estilos visuais.\n",
    "\n",
    "O CSS funciona em conjunto com o HTML, onde cada elemento HTML pode ser associado a uma ou mais regras CSS. Essas regras são definidas em um arquivo separado do HTML, chamado de arquivo CSS, ou diretamente no HTML através do atributo \"style\".\n",
    "\n",
    "As regras CSS são compostas por um seletor e um conjunto de declarações. O seletor define qual elemento HTML será estilizado e as declarações definem as propriedades que serão aplicadas ao elemento. Por exemplo, para estilizar todos os parágrafos de um documento HTML, pode-se utilizar o seguinte código CSS:\n",
    "\n",
    "css\n",
    "\n",
    "Copy code\n",
    "\n",
    "p {\n",
    "\n",
    "    font-size: 16px;\n",
    "\n",
    "    color: #333;\n",
    "\n",
    "    line-height: 1.5;\n",
    "    \n",
    "}\n",
    "\n",
    "Nesse exemplo, o seletor é a tag < p>, e as declarações definem que o tamanho da fonte será de 16 pixels, a cor do texto será um tom de cinza (#333) e o espaçamento entre linhas será de 1.5 vezes o tamanho da fonte.\n",
    "\n",
    "Existem diversas propriedades CSS disponíveis, permitindo estilizar os elementos HTML de diversas formas e criar páginas web visualmente atraentes e personalizadas. Alguns exemplos de propriedades CSS incluem:\n",
    "\n",
    "background-color: define a cor de fundo do elemento;\n",
    "font-family: define a fonte utilizada pelo elemento;\n",
    "text-align: define o alinhamento do texto dentro do elemento;\n",
    "margin e padding: definem espaçamentos internos e externos do elemento.\n",
    "Com o uso do CSS, é possível criar layouts complexos, aplicar animações e efeitos visuais, e adaptar a página para diferentes tamanhos de tela e dispositivos. É uma ferramenta essencial para qualquer desenvolvedor web."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Requisições HTTP e Biblioteca requests\n",
    "\n",
    "A comunicação entre um navegador e um servidor acontece através do protocolo HTTP (Hypertext Transfer Protocol), que é a base da World Wide Web. Para acessar uma página na web, o navegador envia uma solicitação (requisição) HTTP para o servidor, que responde com uma mensagem de resposta.\n",
    "\n",
    "O Python oferece uma biblioteca chamada \"Requests\", que simplifica o processo de envio de requisições HTTP e o tratamento de respostas. Com a biblioteca Requests, podemos automatizar esse processo de envio de requisições e tratamento de respostas, facilitando a obtenção de informações da web.\n",
    "\n",
    "A biblioteca Requests é um pacote que podemos instalar facilmente usando pip (gerenciador de pacotes do Python) e importar para nossos scripts Python. Uma vez importada, podemos usar suas funções e métodos para enviar requisições HTTP, lidar com cookies, autenticação, entre outros.\n",
    "\n",
    "Vamos ver um exemplo simples de como fazer uma requisição HTTP usando a biblioteca Requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"pt-BR\"><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){window.google={kEI:\\'C3daZP3iL5uH4dUP0aWr4AY\\',kEXPI:\\'0,1359409,6059,206,4804,2316,383,246,5,1129120,1197702,380789,16114,19397,9287,22431,1361,12318,2817,14764,4998,13228,3847,6885,32448,1983,2891,4140,7614,606,29880,1,46565,3,346,230,20583,4,1528,2304,29062,13065,18095,16786,5812,2545,4094,7596,1,42154,2,14022,2373,23366,5679,1020,31123,4567,6253,23424,1252,5835,14968,4332,5017,2467,445,2,2,1,24626,2006,8155,7381,1479,14490,874,7828,11805,7,1922,9779,36154,6305,2007,18191,5797,11,14329,14,82,19404,802,3370,5007,18960,578,1728,3097,3030,6110,3226,1815,4665,1804,6250,4222,493,2391,162,2333,17246,10958,3014,13,1250,382,7951,2279,2192,1439,1128,7344,1290,1098,6,483,1492,749,1546,1062,274,2776,164,412,335,1643,494,2012,325,1,598,93,379,2,297,1644,1918,819,170,484,488,512,135,284,622,227,3635,110,124,463,636,3,321,46,214,137,247,87,2,477,94,1048,254,118,434,569,206,2,10,535,15,5,100,1877,5206191,450,262,198,359,7,8798279,3311,141,795,19735,1,1,346,5078,17,34,2,488,7,9,59,43,125,23944623,396,4041746,1964,16673,2893,6250,14715,1025,1415056,146987,23612966,83,95,133,816,68,518,100,85,423,87,950,107,84,260,180,243,254,2,206,2,157,1416,168,363,1035,125,5,1237,580,410,487,206,11,582,291,400,586,436,25,560,737,459,708,99,645,276,61,202,1,6,31,390,323,154,96,101,4,15,1631,1305\\',kBL:\\'Xw_a\\',kOPI:89978449};google.sn=\\'webhp\\';google.kHL=\\'pt-BR\\';})();(function(){\\nvar h=this||self;function l(){return void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null};var m,n=[];function p(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||m}function q(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b}function r(a){/^http:/i.test(a)&&\"https:\"===window.location.protocol&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction t(a,b,c,d,k){var e=\"\";-1===b.search(\"&ei=\")&&(e=\"&ei=\"+p(d),-1===b.search(\"&lei=\")&&(d=q(d))&&(e+=\"&lei=\"+d));d=\"\";var g=-1===b.search(\"&cshid=\")&&\"slh\"!==a,f=[];f.push([\"zx\",Date.now().toString()]);h._cshid&&g&&f.push([\"cshid\",h._cshid]);c=c();null!=c&&f.push([\"opi\",c.toString()]);for(c=0;c<f.length;c++){if(0===c||0<c)d+=\"&\";d+=f[c][0]+\"=\"+f[c][1]}return\"/\"+(k||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(b+e+d)};m=google.kEI;google.getEI=p;google.getLEI=q;google.ml=function(){return null};google.log=function(a,b,c,d,k,e){e=void 0===e?l:e;c||(c=t(a,b,e,d,k));if(c=r(c)){a=new Image;var g=n.length;n[g]=a;a.onerror=a.onload=a.onabort=function(){delete n[g]};a.src=c}};google.logUrl=function(a,b){b=void 0===b?l:b;return t(\"\",a,b)};}).call(this);(function(){google.y={};google.sy=[];google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.sx=function(a){google.sy.push(a)};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};google.bx=!1;google.lx=function(){};}).call(this);google.f={};(function(){\\ndocument.documentElement.addEventListener(\"submit\",function(b){var a;if(a=b.target){var c=a.getAttribute(\"data-submitfalse\");a=\"1\"===c||\"q\"===c&&!a.elements.q.value?!0:!1}else a=!1;a&&(b.preventDefault(),b.stopPropagation())},!0);document.documentElement.addEventListener(\"click\",function(b){var a;a:{for(a=b.target;a&&a!==document.documentElement;a=a.parentElement)if(\"A\"===a.tagName){a=\"1\"===a.getAttribute(\"data-nohref\");break a}a=!1}a&&b.preventDefault()},!0);}).call(this);</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\\n</style><style>body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#1558d6}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px arial,sans-serif}.gsfs{font:17px arial,sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}body{background:#fff;color:#000}a{color:#4b11a8;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#1558d6}a:visited{color:#4b11a8}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#f8f9fa;border:solid 1px;border-color:#dadce0 #70757a #70757a #dadce0;height:30px}.lsbb{display:block}#WqQANb a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;border:none;color:#000;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top}.lsb:active{background:#dadce0}.lst:focus{outline:none}.Ucigb{width:458px}</style><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){window.google.erd={jsr:1,bv:1789,de:true};\\nvar h=this||self;var k,l=null!=(k=h.mei)?k:1,n,p=null!=(n=h.sdo)?n:!0,q=0,r,t=google.erd,v=t.jsr;google.ml=function(a,b,d,m,e){e=void 0===e?2:e;b&&(r=a&&a.message);if(google.dl)return google.dl(a,e,d),null;if(0>v){window.console&&console.error(a,d);if(-2===v)throw a;b=!1}else b=!a||!a.message||\"Error loading script\"===a.message||q>=l&&!m?!1:!0;if(!b)return null;q++;d=d||{};b=encodeURIComponent;var c=\"/gen_204?atyp=i&ei=\"+b(google.kEI);google.kEXPI&&(c+=\"&jexpid=\"+b(google.kEXPI));c+=\"&srcpg=\"+b(google.sn)+\"&jsr=\"+b(t.jsr)+\"&bver=\"+b(t.bv);var f=a.lineNumber;void 0!==f&&(c+=\"&line=\"+f);var g=\\na.fileName;g&&(0<g.indexOf(\"-extension:/\")&&(e=3),c+=\"&script=\"+b(g),f&&g===window.location.href&&(f=document.documentElement.outerHTML.split(\"\\\\n\")[f],c+=\"&cad=\"+b(f?f.substring(0,300):\"No script found.\")));c+=\"&jsel=\"+e;for(var u in d)c+=\"&\",c+=b(u),c+=\"=\",c+=b(d[u]);c=c+\"&emsg=\"+b(a.name+\": \"+a.message);c=c+\"&jsst=\"+b(a.stack||\"N/A\");12288<=c.length&&(c=c.substr(0,12288));a=c;m||google.log(0,\"\",a);return a};window.onerror=function(a,b,d,m,e){r!==a&&(a=e instanceof Error?e:Error(a),void 0===d||\"lineNumber\"in a||(a.lineNumber=d),void 0===b||\"fileName\"in a||(a.fileName=b),google.ml(a,!1,void 0,!1,\"SyntaxError\"===a.name||\"SyntaxError\"===a.message.substring(0,11)||-1!==a.message.indexOf(\"Script error\")?3:0));r=null;p&&q>=l&&(window.onerror=null)};})();</script></head><body bgcolor=\"#fff\"><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){var src=\\'/images/nav_logo229.png\\';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\\nif (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\\n}\\n})();</script><div id=\"mngb\"><div id=gbar><nobr><b class=gb1>Pesquisa</b> <a class=gb1 href=\"https://www.google.com.br/imghp?hl=pt-BR&tab=wi\">Imagens</a> <a class=gb1 href=\"https://maps.google.com.br/maps?hl=pt-BR&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=pt-BR&tab=w8\">Play</a> <a class=gb1 href=\"https://www.youtube.com/?tab=w1\">YouTube</a> <a class=gb1 href=\"https://news.google.com/?tab=wn\">Not\\xedcias</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.com.br/intl/pt-BR/about/products?tab=wh\"><u>Mais</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.com.br/history/optout?hl=pt-BR\" class=gb4>Hist\\xf3rico da Web</a> | <a  href=\"/preferences?hl=pt-BR\" class=gb4>Configura\\xe7\\xf5es</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=pt-BR&passive=true&continue=https://www.google.com/&ec=GAZAAQ\" class=gb4>Fazer login</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div></div><center><br clear=\"all\" id=\"lgpd\"><div id=\"lga\"><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"pt-BR\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><div style=\"position:relative;zoom:1\"><input class=\"lst Ucigb\" style=\"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#000;padding-right:38px\" autocomplete=\"off\" value=\"\" title=\"Pesquisa Google\" maxlength=\"2048\" name=\"q\" size=\"57\"><img src=\"/textinputassistant/tia.png\" style=\"position:absolute;cursor:pointer;right:5px;top:4px;z-index:300\" data-script-url=\"/textinputassistant/11/pt-BR_tia.js\" id=\"tsuid_1\" alt=\"\" height=\"23\" width=\"27\"><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){var id=\\'tsuid_1\\';document.getElementById(id).onclick = function(){var s = document.createElement(\\'script\\');s.src = this.getAttribute(\\'data-script-url\\');(document.getElementById(\\'xjsc\\')||document.body).appendChild(s);};})();</script></div></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Pesquisa Google\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid_2\" value=\"Estou com sorte\" name=\"btnI\" type=\"submit\"><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){var id=\\'tsuid_2\\';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\\nelse top.location=\\'/doodles/\\';};})();</script><input value=\"AOEireoAAAAAZFqFG7qENxM1WMNNMXXYuIlMOaVv0QIo\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=pt-BR&amp;authuser=0\">Pesquisa avan\\xe7ada</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(\"undefined\"!=typeof XMLHttpRequest)b=\"2\";else if(\"undefined\"!=typeof ActiveXObject){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(\"2\"==a&&-1==location.search.indexOf(\"&gbv=2\")){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div id=\"gac_scont\"></div><div style=\"font-size:83%;min-height:3.5em\"><br></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"WqQANb\"><a href=\"/intl/pt-BR/ads/\">Publicidade</a><a href=\"/services/\">Solu\\xe7\\xf5es empresariais</a><a href=\"/intl/pt-BR/about.html\">Sobre o Google</a><a href=\"https://www.google.com/setprefdomain?prefdom=BR&amp;prev=https://www.google.com.br/&amp;sig=K_YQHpYcD5MCFKWbMVI-c5UTqTmOY%3D\">Google.com.br</a></div></div><p style=\"font-size:8pt;color:#70757a\">&copy; 2023 - <a href=\"/intl/pt-BR/policies/privacy/\">Privacidade</a> - <a href=\"/intl/pt-BR/policies/terms/\">Termos</a></p></span></center><script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){window.google.cdo={height:757,width:1440};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=\"CSS1Compat\"==c.compatMode?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}\\nif(a&&b&&(a!=google.cdo.width||b!=google.cdo.height)){var e=google,f=e.log,g=\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI,h=\"\",k=[],l=void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null;null!=l&&k.push([\"opi\",l.toString()]);for(var m=0;m<k.length;m++){if(0===m||0<m)h+=\"&\";h+=k[m][0]+\"=\"+k[m][1]}f.call(e,\"\",\"\",g+h)};}).call(this);})();</script> <script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){google.xjs={ck:\\'xjs.hp.vUsZk7fd8do.L.X.O\\',cs:\\'ACT90oHvNKf0VndSCQCbyvBm-VFWBpF2tQ\\',excm:[]};})();</script>  <script nonce=\"xDJm5AAGXQeT-rxJLK1Qjg\">(function(){var u=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.CULboG5sOro.O/am\\\\x3dAAAA6AQAUABgAQ/d\\\\x3d1/ed\\\\x3d1/rs\\\\x3dACT90oFZxVOwITafXDZCzqnHTQ0_Y7i2BA/m\\\\x3dsb_he,d\\';var amd=0;\\nvar e=this||self,f=function(c){return c};var g;var k=function(c){this.g=c};k.prototype.toString=function(){return this.g+\"\"};var m={};\\nfunction q(){var c=u,n=function(){};google.lx=google.stvsc?n:function(){google.timers&&google.timers.load&&google.tick&&google.tick(\"load\",\"xjsls\");var a=document;var b=\"SCRIPT\";\"application/xhtml+xml\"===a.contentType&&(b=b.toLowerCase());b=a.createElement(b);a=null===c?\"null\":void 0===c?\"undefined\":c;if(void 0===g){var d=null;var l=e.trustedTypes;if(l&&l.createPolicy){try{d=l.createPolicy(\"goog#html\",{createHTML:f,createScript:f,createScriptURL:f})}catch(r){e.console&&e.console.error(r.message)}g=\\nd}else g=d}a=(d=g)?d.createScriptURL(a):a;a=new k(a,m);b.src=a instanceof k&&a.constructor===k?a.g:\"type_error:TrustedResourceUrl\";var h,p;(h=(a=null==(p=(h=(b.ownerDocument&&b.ownerDocument.defaultView||window).document).querySelector)?void 0:p.call(h,\"script[nonce]\"))?a.nonce||a.getAttribute(\"nonce\")||\"\":\"\")&&b.setAttribute(\"nonce\",h);document.body.appendChild(b);google.psa=!0;google.lx=n};google.bx||google.lx()};google.xjsu=u;e._F_jsUrl=u;setTimeout(function(){0<amd?google.caft(function(){return q()},amd):q()},0);})();window._ = window._ || {};window._DumpException = _._DumpException = function(e){throw e;};window._s = window._s || {};_s._DumpException = _._DumpException;window._qs = window._qs || {};_qs._DumpException = _._DumpException;function _F_installCss(c){}\\n(function(){google.jl={blt:\\'none\\',chnk:0,dw:false,dwu:true,emtn:0,end:0,ico:false,ikb:0,ine:false,injs:\\'none\\',injt:0,injth:0,injv2:false,lls:\\'default\\',pdt:0,rep:0,snet:true,strt:0,ubm:false,uwp:true};})();(function(){var pmc=\\'{\\\\x22d\\\\x22:{},\\\\x22sb_he\\\\x22:{\\\\x22agen\\\\x22:true,\\\\x22cgen\\\\x22:true,\\\\x22client\\\\x22:\\\\x22heirloom-hp\\\\x22,\\\\x22dh\\\\x22:true,\\\\x22ds\\\\x22:\\\\x22\\\\x22,\\\\x22fl\\\\x22:true,\\\\x22host\\\\x22:\\\\x22google.com\\\\x22,\\\\x22jsonp\\\\x22:true,\\\\x22msgs\\\\x22:{\\\\x22cibl\\\\x22:\\\\x22Limpar pesquisa\\\\x22,\\\\x22dym\\\\x22:\\\\x22Voc\\\\\\\\u00ea quis dizer:\\\\x22,\\\\x22lcky\\\\x22:\\\\x22Estou com sorte\\\\x22,\\\\x22lml\\\\x22:\\\\x22Saiba mais\\\\x22,\\\\x22psrc\\\\x22:\\\\x22Esta pesquisa foi removida do seu\\\\\\\\u003Ca href\\\\x3d\\\\\\\\\\\\x22/history\\\\\\\\\\\\x22\\\\\\\\u003EHist\\\\\\\\u00f3rico da web\\\\\\\\u003C/a\\\\\\\\u003E\\\\x22,\\\\x22psrl\\\\x22:\\\\x22Remover\\\\x22,\\\\x22sbit\\\\x22:\\\\x22Pesquisa por imagem\\\\x22,\\\\x22srch\\\\x22:\\\\x22Pesquisa Google\\\\x22},\\\\x22ovr\\\\x22:{},\\\\x22pq\\\\x22:\\\\x22\\\\x22,\\\\x22rfs\\\\x22:[],\\\\x22sbas\\\\x22:\\\\x220 3px 8px 0 rgba(0,0,0,0.2),0 0 0 1px rgba(0,0,0,0.08)\\\\x22,\\\\x22stok\\\\x22:\\\\x22H8gprzeEFuKeHRgLPFkELfXw2JE\\\\x22}}\\';google.pmc=JSON.parse(pmc);})();</script>       </body></html>'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://www.google.com\")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, estamos fazendo uma requisição HTTP usando o método GET para acessar a página inicial do Google. O método requests.get() retorna um objeto do tipo Response, que contém várias informações sobre a resposta recebida do servidor, como o código de status, o conteúdo da resposta e os headers.\n",
    "\n",
    "Estamos imprimindo o conteúdo da resposta com o método content, que retorna o conteúdo da resposta em bytes. Podemos manipular esse conteúdo de várias formas, como converter para texto, analisar com a biblioteca BeautifulSoup, ou salvar em um arquivo.\n",
    "\n",
    "A biblioteca Requests também permite enviar dados através de formulários, autenticar em servidores, e outros recursos que nos permitem explorar a web de forma automatizada.\n",
    "\n",
    "Lembrando que ao fazer requisições HTTP, é importante estar ciente das políticas de uso de cada website, pois algumas podem proibir o acesso automatizado ou impor limites de acesso. É importante respeitar essas políticas para evitar problemas legais ou bloqueios de acesso."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 O que é uma requisição HTTP?\n",
    "\n",
    "O protocolo HTTP (Hypertext Transfer Protocol) é um protocolo utilizado na comunicação entre clientes e servidores na web. As requisições HTTP são utilizadas para solicitar dados e informações de um servidor web para serem exibidos em um navegador.\n",
    "\n",
    "Basicamente, uma requisição HTTP consiste em um cabeçalho e um corpo. O cabeçalho contém informações sobre a requisição, como o tipo de método utilizado (GET, POST, PUT, DELETE, etc.), a URL do servidor, e informações sobre o cliente que está fazendo a requisição. O corpo da requisição é opcional e é utilizado para enviar dados do cliente para o servidor, como informações de formulário.\n",
    "\n",
    "Por exemplo, se você digitar uma URL em seu navegador, o navegador envia uma requisição HTTP para o servidor do site correspondente, solicitando a página da web. O servidor responde a essa requisição, enviando o HTML da página de volta para o navegador, que o exibe para você.\n",
    "\n",
    "É importante entender as requisições HTTP para trabalhar com Web Scraping, pois muitas vezes precisamos enviar requisições para obter os dados que queremos raspar de um site. A biblioteca requests em Python é uma ferramenta muito útil para enviar e receber requisições HTTP em projetos de Web Scraping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Biblioteca requests em Python\n",
    "\n",
    "A biblioteca requests é uma das mais populares para trabalhar com requisições HTTP em Python. Com ela, podemos facilmente fazer requisições GET, POST, PUT, DELETE, entre outras, e manipular os dados que recebemos de volta.\n",
    "\n",
    "Para utilizá-la, primeiro precisamos instalá-la. Podemos fazer isso pelo gerenciador de pacotes pip, digitando no terminal ou prompt de comando: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de instalada, podemos importá-la em nosso código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer uma requisição HTTP com o método GET, basta utilizar a função requests.get(url), onde url é a URL do recurso que queremos acessar. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://api.github.com/users/octocat\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, estamos acessando a API do GitHub para obter informações do usuário \"octocat\". O objeto response contém os dados que foram retornados pela requisição.\n",
    "\n",
    "Podemos então manipular os dados recebidos. Por exemplo, para obter o conteúdo da resposta como uma string, podemos utilizar o atributo text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"login\":\"octocat\",\"id\":583231,\"node_id\":\"MDQ6VXNlcjU4MzIzMQ==\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/583231?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/octocat\",\"html_url\":\"https://github.com/octocat\",\"followers_url\":\"https://api.github.com/users/octocat/followers\",\"following_url\":\"https://api.github.com/users/octocat/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/octocat/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/octocat/subscriptions\",\"organizations_url\":\"https://api.github.com/users/octocat/orgs\",\"repos_url\":\"https://api.github.com/users/octocat/repos\",\"events_url\":\"https://api.github.com/users/octocat/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/octocat/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"The Octocat\",\"company\":\"@github\",\"blog\":\"https://github.blog\",\"location\":\"San Francisco\",\"email\":null,\"hireable\":null,\"bio\":null,\"twitter_username\":null,\"public_repos\":8,\"public_gists\":8,\"followers\":9155,\"following\":9,\"created_at\":\"2011-01-25T18:44:36Z\",\"updated_at\":\"2023-04-22T11:18:59Z\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter o conteúdo como um objeto JSON, podemos utilizar o atributo json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Octocat\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "print(data[\"name\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além do método GET, a biblioteca requests também nos permite fazer outras requisições HTTP, como POST, PUT e DELETE. Para isso, basta utilizar as funções requests.post(url), requests.put(url) e requests.delete(url), respectivamente, passando a URL e os dados a serem enviados, se necessário.\n",
    "\n",
    "O uso da biblioteca requests torna a manipulação de requisições HTTP em Python mais fácil e eficiente, e é uma ferramenta importante para o web scraping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.3 Fazendo uma requisição HTTP em Python\n",
    "\n",
    "Para fazer uma requisição HTTP em Python utilizando a biblioteca requests, é necessário seguir alguns passos simples:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Importar a biblioteca requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Utilizar o método get() para fazer a requisição HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.example.com')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, estamos fazendo uma requisição HTTP para o website https://www.example.com."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Verificar o código de status da resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem sucedida!\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print('Requisição bem sucedida!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código de status 200 indica que a requisição foi bem sucedida."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Acessar o conteúdo da resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html>\\n<head>\\n    <title>Example Domain</title>\\n\\n    <meta charset=\"utf-8\" />\\n    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <style type=\"text/css\">\\n    body {\\n        background-color: #f0f0f2;\\n        margin: 0;\\n        padding: 0;\\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\\n        \\n    }\\n    div {\\n        width: 600px;\\n        margin: 5em auto;\\n        padding: 2em;\\n        background-color: #fdfdff;\\n        border-radius: 0.5em;\\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\\n    }\\n    a:link, a:visited {\\n        color: #38488f;\\n        text-decoration: none;\\n    }\\n    @media (max-width: 700px) {\\n        div {\\n            margin: 0 auto;\\n            width: auto;\\n        }\\n    }\\n    </style>    \\n</head>\\n\\n<body>\\n<div>\\n    <h1>Example Domain</h1>\\n    <p>This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.</p>\\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conteúdo da resposta pode ser acessado através do atributo content.\n",
    "\n",
    "Além do método get(), a biblioteca requests também possui outros métodos para fazer requisições HTTP, como o post() e o put(), por exemplo. É importante também tratar possíveis erros ao fazer requisições HTTP, utilizando blocos try/except para lidar com exceções que possam ocorrer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Tratando erros com try/except\n",
    "\n",
    "Quando fazemos requisições HTTP em Python, é importante considerar que podem ocorrer erros inesperados durante o processo. Por exemplo, a página que estamos tentando acessar pode estar temporariamente indisponível, ou a conexão com a internet pode estar interrompida.\n",
    "\n",
    "Para lidar com essas situações de erro, podemos utilizar o bloco try/except. O try é o bloco em que colocamos o código que queremos tentar executar, e o except é o bloco em que colocamos o código que queremos executar caso ocorra um erro durante a execução do try.\n",
    "\n",
    "Vejamos um exemplo de como usar o try/except ao fazer uma requisição HTTP com a biblioteca requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem-sucedida!\n",
      "{\"login\":\"octocat\",\"id\":583231,\"node_id\":\"MDQ6VXNlcjU4MzIzMQ==\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/583231?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/octocat\",\"html_url\":\"https://github.com/octocat\",\"followers_url\":\"https://api.github.com/users/octocat/followers\",\"following_url\":\"https://api.github.com/users/octocat/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/octocat/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/octocat/subscriptions\",\"organizations_url\":\"https://api.github.com/users/octocat/orgs\",\"repos_url\":\"https://api.github.com/users/octocat/repos\",\"events_url\":\"https://api.github.com/users/octocat/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/octocat/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"The Octocat\",\"company\":\"@github\",\"blog\":\"https://github.blog\",\"location\":\"San Francisco\",\"email\":null,\"hireable\":null,\"bio\":null,\"twitter_username\":null,\"public_repos\":8,\"public_gists\":8,\"followers\":9155,\"following\":9,\"created_at\":\"2011-01-25T18:44:36Z\",\"updated_at\":\"2023-04-22T11:18:59Z\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/users/octocat'\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f'HTTP error occurred: {http_err}')\n",
    "except Exception as err:\n",
    "    print(f'Other error occurred: {err}')\n",
    "else:\n",
    "    print('Requisição bem-sucedida!')\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 404 Client Error: Not Found for url: https://api.github.com/users/octocat/ide.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/users/octocat/ide.csv'\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f'HTTP error occurred: {http_err}')\n",
    "except Exception as err:\n",
    "    print(f'Other error occurred: {err}')\n",
    "else:\n",
    "    print('Requisição bem-sucedida!')\n",
    "    print(response.text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, fazemos uma requisição HTTP com a biblioteca requests para o site https://api.github.com/users/octocat. Em seguida, colocamos o código dentro do bloco try. Se a requisição for bem-sucedida, o código dentro do bloco else será executado, e o conteúdo da página será impresso na tela.\n",
    "\n",
    "No entanto, se ocorrer um erro durante a requisição, o bloco except será executado. Se o erro for uma exceção HTTPError, que é uma exceção específica para erros HTTP, o código dentro do primeiro bloco except será executado e uma mensagem de erro HTTP será impressa na tela. Se ocorrer qualquer outro tipo de exceção, o código dentro do segundo bloco except será executado, e uma mensagem genérica de erro será impressa na tela."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Analisando HTML com Beautiful Soup\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 O que é Beautiful Soup?\n",
    "\n",
    "Beautiful Soup é uma biblioteca Python utilizada para extrair informações de arquivos HTML e XML. Ela permite que você analise o conteúdo de uma página da web e encontre elementos específicos com facilidade, tornando mais fácil a criação de um web scraper.\n",
    "\n",
    "A biblioteca recebe uma string contendo o código HTML e a transforma em um objeto que pode ser percorrido e manipulado através de métodos Python. É uma ferramenta bastante flexível, permitindo diferentes estratégias de busca e extração de dados.\n",
    "\n",
    "Além disso, a Beautiful Soup tem uma documentação bem completa e é fácil de aprender, o que a torna uma escolha popular entre desenvolvedores e cientistas de dados que desejam extrair dados de sites da web."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analisando HTML com Beautiful Soup\n",
    "Beautiful Soup é uma biblioteca Python que nos permite analisar e extrair dados de documentos HTML e XML de maneira fácil e eficiente. Com Beautiful Soup, podemos facilmente buscar e extrair informações específicas de uma página da web.\n",
    "\n",
    "Para analisar um documento HTML com Beautiful Soup, precisamos seguir alguns passos básicos:\n",
    "\n",
    "1 - Fazer uma requisição HTTP para obter o conteúdo HTML da página\n",
    "\n",
    "2 - Criar um objeto BeautifulSoup a partir do conteúdo HTML\n",
    "\n",
    "3 - Utilizar os métodos e atributos do objeto BeautifulSoup para extrair as informações desejadas\n",
    "\n",
    "Vamos ver um exemplo simples de como analisar um documento HTML usando Beautiful Soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Domain\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fazer uma requisição HTTP para obter o conteúdo HTML da página\n",
    "url = 'https://www.example.com'\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Criar um objeto BeautifulSoup a partir do conteúdo HTML\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Utilizar os métodos e atributos do objeto BeautifulSoup para extrair as informações desejadas\n",
    "title = soup.title.text\n",
    "print(title)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, estamos fazendo uma requisição HTTP para obter o conteúdo HTML da página https://www.example.com. Em seguida, criamos um objeto BeautifulSoup a partir do conteúdo HTML usando o parser html.parser. Finalmente, utilizamos o atributo title do objeto BeautifulSoup para extrair o título da página e imprimimos na tela."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Buscando elementos HTML específicos\n",
    "\n",
    "Para buscar elementos HTML específicos com o Beautiful Soup, podemos utilizar diferentes métodos e atributos disponíveis na biblioteca.\n",
    "\n",
    "Um dos métodos mais comuns é o find, que busca a primeira ocorrência do elemento especificado. Por exemplo, se quisermos buscar a primeira ocorrência de uma tag h1 em uma página, podemos utilizar o seguinte código:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"ytd-searchbox-spt\" id=\"search-container\" slot=\"search-container\"></div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://youtube.com.br'\n",
    "resposta = requests.get(url)\n",
    "soup = BeautifulSoup(resposta.content, 'html.parser')\n",
    "\n",
    "titulo = soup.find('div')\n",
    "print(titulo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima faz uma requisição HTTP para a URL especificada e utiliza o Beautiful Soup para analisar o conteúdo HTML retornado. Em seguida, utilizamos o método find para buscar a primeira ocorrência da tag h1. O resultado é armazenado na variável titulo, que pode ser impressa na tela ou utilizada de outras maneiras.\n",
    "\n",
    "Além do método find, existem outros métodos e atributos disponíveis no Beautiful Soup para buscar elementos HTML específicos, como o find_all (para buscar todas as ocorrências de um elemento), o select (para buscar elementos com base em um seletor CSS) e diversos outros."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tratando erros com try/except\n",
    "\n",
    "Tratar erros é uma parte importante de qualquer programa, e isso inclui o código de web scraping. Às vezes, quando você tenta buscar um elemento específico em uma página, pode ocorrer algum erro, como a página não estar carregando corretamente ou o elemento não existir.\n",
    "\n",
    "Para lidar com esses erros, podemos usar o bloco try/except do Python. Esse bloco permite que o programa tente executar uma determinada ação e, caso ocorra um erro, o programa não pare completamente. Em vez disso, podemos lidar com o erro de maneira apropriada e continuar a execução do programa.\n",
    "\n",
    "Por exemplo, suponha que você esteja buscando um elemento específico em uma página da web usando Beautiful Soup, mas esse elemento pode ou não estar presente na página. Podemos usar o bloco try/except para lidar com essa situação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O elemento não foi encontrado\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://youtube.com.br'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "try:\n",
    "    element = soup.find('div', {'class': 'classe_do_elemento'})\n",
    "    print(element.text)\n",
    "except AttributeError:\n",
    "    print('O elemento não foi encontrado')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, estamos tentando buscar um elemento div com a classe classe_do_elemento na página https://www.exemplo.com. Se o elemento for encontrado, o texto dentro dele será impresso. Caso contrário, será impressa a mensagem 'O elemento não foi encontrado'.\n",
    "\n",
    "Ao usar o bloco try/except, estamos tornando nosso código mais robusto e resistente a falhas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Armazenamento de dados\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Formatos de dados comuns\n",
    "\n",
    "Existem diversos formatos de dados comuns utilizados na comunicação de sistemas, alguns dos principais são:\n",
    "\n",
    "1 - JSON (JavaScript Object Notation): é um formato de dados leve e independente de linguagem de programação, amplamente utilizado para comunicação de dados na web. Possui uma estrutura simples de chave-valor e suporta vários tipos de dados como string, número, booleano, objeto e array.\n",
    "\n",
    "Exemplo de JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nome': 'João',\n",
       " 'idade': 30,\n",
       " 'email': 'joao@email.com',\n",
       " 'telefones': ['(11) 1234-5678', '(11) 9876-5432']}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"nome\": \"João\",\n",
    "    \"idade\": 30,\n",
    "    \"email\": \"joao@email.com\",\n",
    "    \"telefones\": [\"(11) 1234-5678\", \"(11) 9876-5432\"]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - XML (Extensible Markup Language): é uma linguagem de marcação para documentos que contém dados estruturados, permitindo que sejam facilmente processados por máquinas. Também é independente de linguagem de programação e tem como vantagem a possibilidade de validação do documento com um schema.\n",
    "\n",
    "Exemplo de XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<pessoa>\\n    <nome>João</nome>\\n    <idade>30</idade>\\n    <email>joao@email.com</email>\\n    <telefones>\\n        <telefone>(11) 1234-5678</telefone>\\n        <telefone>(11) 9876-5432</telefone>\\n    </telefones>\\n</pessoa>\\n\\n'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "<pessoa>\n",
    "    <nome>João</nome>\n",
    "    <idade>30</idade>\n",
    "    <email>joao@email.com</email>\n",
    "    <telefones>\n",
    "        <telefone>(11) 1234-5678</telefone>\n",
    "        <telefone>(11) 9876-5432</telefone>\n",
    "    </telefones>\n",
    "</pessoa>\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - CSV (Comma-Separated Values): é um formato de texto que representa dados em forma de tabela, em que cada linha corresponde a um registro e as colunas são separadas por vírgulas. É um formato simples e de fácil entendimento, podendo ser facilmente manipulado em planilhas.\n",
    "\n",
    "Exemplo de CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nnome,idade,email,telefones\\nJoão,30,joao@email.com,\"(11) 1234-5678, (11) 9876-5432\"\\n\\n'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "nome,idade,email,telefones\n",
    "João,30,joao@email.com,\"(11) 1234-5678, (11) 9876-5432\"\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - YAML (YAML Ain't Markup Language): é um formato de dados simples e legível por humanos, com uma estrutura hierárquica que utiliza espaços em branco para indicar a hierarquia. É utilizado principalmente em configurações de sistemas e linguagens de programação.\n",
    "\n",
    "Exemplo de YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nnome: João\\nidade: 30\\nemail: joao@email.com\\ntelefones:\\n  - (11) 1234-5678\\n  - (11) 9876-5432\\n  \\n'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "nome: João\n",
    "idade: 30\n",
    "email: joao@email.com\n",
    "telefones:\n",
    "  - (11) 1234-5678\n",
    "  - (11) 9876-5432\n",
    "  \n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Armazenando dados em um arquivo CSV\n",
    "\n",
    "CSV (Comma Separated Values) é um formato de arquivo amplamente utilizado para armazenar e transmitir dados tabulares. É especialmente útil para armazenar grandes quantidades de dados que precisam ser facilmente compartilhados entre diferentes sistemas e aplicativos.\n",
    "\n",
    "O Python tem uma biblioteca padrão chamada csv que facilita a leitura e gravação de dados em arquivos CSV. Para armazenar dados em um arquivo CSV, podemos seguir os seguintes passos:\n",
    "\n",
    "Importar a biblioteca csv\n",
    "Abrir o arquivo CSV para escrita\n",
    "Escrever as linhas de dados no arquivo CSV\n",
    "Fechar o arquivo CSV\n",
    "Aqui está um exemplo simples que escreve uma lista de dicionários em um arquivo CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [\n",
    "    {'Nome': 'João', 'Idade': 25, 'Profissão': 'Engenheiro'},\n",
    "    {'Nome': 'Maria', 'Idade': 30, 'Profissão': 'Professor'},\n",
    "    {'Nome': 'Pedro', 'Idade': 35, 'Profissão': 'Programador'}\n",
    "]\n",
    "\n",
    "# Abre o arquivo CSV para escrita\n",
    "with open('dados.csv', mode='w', newline='') as arquivo_csv:\n",
    "    # Cria o escritor CSV\n",
    "    escritor = csv.DictWriter(arquivo_csv, fieldnames=['Nome', 'Idade', 'Profissão'])\n",
    "\n",
    "    # Escreve o cabeçalho\n",
    "    escritor.writeheader()\n",
    "\n",
    "    # Escreve os dados\n",
    "    for linha in data:\n",
    "        escritor.writerow(linha)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, primeiro importamos a biblioteca csv. Em seguida, criamos uma lista de dicionários chamada data, que contém os dados que queremos armazenar em um arquivo CSV. Então, abrimos o arquivo CSV para escrita usando a função open, especificando o modo \"w\" para escrita e o argumento newline='' para evitar que linhas em branco sejam adicionadas ao arquivo.\n",
    "\n",
    "Em seguida, criamos um objeto escritor CSV usando a classe DictWriter da biblioteca csv. Especificamos os nomes dos campos usando a lista fieldnames. Em seguida, escrevemos o cabeçalho do arquivo CSV usando o método writeheader.\n",
    "\n",
    "Finalmente, usamos um loop for para escrever cada linha de dados no arquivo CSV usando o método writerow do objeto escritor CSV.\n",
    "\n",
    "Depois de escrever todas as linhas de dados, fechamos o arquivo CSV usando o método close ou o bloco with. Agora, temos um arquivo CSV chamado dados.csv que contém nossos dados tabulares."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Armazenando dados em um banco de dados\n",
    "\n",
    "Armazenar dados em um banco de dados é uma opção mais robusta e escalável do que armazená-los em um arquivo CSV. Existem vários tipos de bancos de dados que podem ser usados para armazenar dados, como bancos de dados relacionais (SQL) e bancos de dados NoSQL. Nesta resposta, vamos nos concentrar em um exemplo simples de armazenamento de dados em um banco de dados relacional usando o SQLite e a biblioteca sqlite3 do Python.\n",
    "\n",
    "Antes de começar, é necessário ter o SQLite instalado em seu sistema. Para verificar se o SQLite já está instalado, abra o terminal e digite \"sqlite3\". Se o SQLite estiver instalado, você verá a linha de comando do SQLite. Caso contrário, você pode instalar o SQLite seguindo as instruções do site oficial (https://www.sqlite.org/download.html).\n",
    "\n",
    "Depois de ter o SQLite instalado, você pode usar a biblioteca sqlite3 do Python para se conectar a um banco de dados SQLite e executar consultas SQL. Aqui está um exemplo simples de como criar uma tabela e inserir dados nela usando o sqlite3:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Conectar-se ao banco de dados\n",
    "conn = sqlite3.connect('exemplo.db')\n",
    "\n",
    "# Criar uma tabela\n",
    "conn.execute('''CREATE TABLE clientes\n",
    "             (ID INT PRIMARY KEY NOT NULL,\n",
    "             NOME TEXT NOT NULL,\n",
    "             EMAIL TEXT NOT NULL);''')\n",
    "\n",
    "# Inserir dados na tabela\n",
    "conn.execute(\"INSERT INTO clientes (ID,NOME,EMAIL) \\\n",
    "              VALUES (1, 'João', 'joao@email.com')\")\n",
    "\n",
    "# Salvar as alterações\n",
    "conn.commit()\n",
    "\n",
    "# Fechar a conexão\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, criamos uma tabela chamada \"clientes\" com três colunas: \"ID\", \"NOME\" e \"EMAIL\". Em seguida, inserimos um registro na tabela com os valores 1, \"João\" e \"joao@email.com\".\n",
    "\n",
    "Você pode verificar se os dados foram inseridos corretamente executando a seguinte consulta SQL no SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'João', 'joao@email.com')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Estabelece uma conexão com o banco de dados\n",
    "conn = sqlite3.connect('exemplo.db')\n",
    "\n",
    "# Cria um cursor para executar consultas\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Executa a consulta\n",
    "cur.execute('SELECT * FROM clientes')\n",
    "\n",
    "# Lê os resultados da consulta\n",
    "for row in cur:\n",
    "    print(row)\n",
    "\n",
    "# Fecha o cursor e a conexão\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta consulta deve retornar o registro que acabamos de inserir na tabela.\n",
    "\n",
    "É importante observar que a biblioteca sqlite3 do Python também pode ser usada para executar outras consultas SQL, como SELECT, UPDATE, DELETE, etc., permitindo que você interaja com o banco de dados de várias maneiras. Além disso, você pode usar outras bibliotecas Python para se conectar a outros tipos de bancos de dados, como o MySQL e o PostgreSQL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
